# Responsible AI

As AI becomes more common, many technologies that aren't AI enabled may start to seem inadequate.
Now, AI systems are enabling computers to see, understand, and interact with the world in ways that were unimaginable just a decade ago.
These systems are developing at an extraordinary pace.

Yet, despite these remarkable advancements, AI is not **infallible**.


![ResAI_1](https://github.com/nildenist/Generative-AI/assets/28653377/17b5945c-9e57-4ea5-8f72-ff77bacb2bf8)

Technology is a reflection of what exist in society.

![resAI_2](https://github.com/nildenist/Generative-AI/assets/28653377/bbab9ac1-6fd5-4036-90d2-6ec6ca1eb55d)

Without good practices, AI may replicate existing issues or bias and amplify them.

## Definition of Responsible AI

There isn't a universal definition of responsible AI, nor is there a simple checklist or formula that defines how responsible AI practices should be implemented.
Instead, organizations are developing their own AI principles that reflect their mission and values.


![chrome-capture-2023-9-10 (2)](https://github.com/nildenist/Generative-AI/assets/28653377/a9b7838a-469d-415c-be2f-fa1638b4f54c) 

While these principles are unique to every organization, if you look for common themes, you find a consistent set of ideas across **transparency**, **fairness**, **accountability**, and **privacy**.

Google's approach to responsible AI is rooted in a commitment, to strive towards AI that's built for everyone that's accountable and safe, that respects privacy, and that is driven by scientific excellence.Google has developed its own AI principles, practices, governance processes, and tools that together embody its values and guide its approach to responsible AI.

Google has incorporated responsibility by design into its products, and even more importantly its organization.

![chrome-capture-2023-9-10 (3)](https://github.com/nildenist/Generative-AI/assets/28653377/30681b17-c0db-436d-aca2-37cc7c9a66e8)


Google all has a role to play in how responsible AI is applied. Whatever stage in the AI process you're involved with, from **design** to **deployment** or **application**, the decisions you make have an impact. Therefore, it's important that you too have a <ins>defined</ins> and <ins>repeatable</ins> process for using AI responsibly.

There's a common misconception with artificial intelligence that machines play the central decision-making role. 

In reality, it's people who design and build these machines, and decide how they're used.
People are involved in each aspect of AI development.
They collect or create the data that the model is trained on.
They control the deployment of the AI and how it's applied in a given context.
Essentially, human decisions are threaded throughout our technology products.
Every time a person makes a decision, they're actually making a choice based on their own values.
Whether it's the decision to use generative AI to solve a problem as opposed to other methods, or anywhere throughout the machine learning life cycle, that person introduces their own set of values.

This means that every decision point requires **consideration** and **evaluation** to ensure that choices have been made **responsibly** from concept through deployment and maintenance.

![chrome-capture-2023-9-10 (4)](https://github.com/nildenist/Generative-AI/assets/28653377/b1f81bed-a09a-434c-8c7d-95fd86e776bd)

Because there's potential to impact many areas of society, not to mention people's daily lives, it's important to develop these technologies with ethics in mind.

Responsible AI doesn't mean to focus only on the obviously controversial use cases.

***Without Responsible AI practices, even seemingly innocuous AI use cases, or those with good intent could still cause ethical issues or unintended outcomes, or not be as beneficial as they could be.***

Ethics and responsibility are important, not least because they represent the right thing to do, but also because they can guide AI designed to be more beneficial for people's lives.

Google has learned that building responsibility into any AI deployment makes better models and builds trust with our customers and our customers customers. 

![chrome-capture-2023-9-10 (5)](https://github.com/nildenist/Generative-AI/assets/28653377/ab71d07d-438e-4bb8-bc46-e5cc4563de77)

If at any point in that trust is broken, we run the risk of AI deployment is being stalled, unsuccessful, or at worst harmful to stakeholders those products affect.


